Many big-data clusters store data in large partitions that support access at a coarse, partition-level granularity. As a result, approximate query processing via row-level sampling is inefficient, often requiring reads of many partitions. In this work, we seek to answer aggregation queries quickly and approximately by reading a subset of the data partitions and combining partial answers in a weighted manner given a pre-partitioned dataset. We illustrate how to efficiently perform this query processing using a set of pre-computed summary statistics, which inform the choice of partition subset and weights. We develop novel means of using the statistics to assess the similarity and importance of partitions. Our experiments on several datasets and data layouts demonstrate an up to 8.5× reduction in the number of partitions that must be read to achieve ≤ 10% relative error compared to sampling the partitions uniformly at random, and the statistics stored per partition require fewer than 100KB.