Big-data systems have gained significant momentum, and Apache Spark is becoming a de-facto standard for modern data analytics. Spark relies on dynamic code generation to optimize the execution performance of SQL queries on a variety of data sources. Despite its already efficient runtime, Spark's code generation suffers from significant runtime overheads related to data de-serialization during query execution. Such performance penalty can be significant, especially when applications operate on human-readable data formats such as CSV or JSON.

In this paper we present a new query compiler for Spark that overcomes these limitations by integrating input data de-serialization within the query execution compiled code and leveraging speculative optimizations and code specialization to optimize predicate evaluation.
Our new SQL compiler for Spark produces highly-efficient machine code, leading to speedups of up to 4.4x on the TPC-H benchmark with textual-form data formats such as CSV or JSON. Such data formats are typically considered inefficient: our work shows that code generation can help closing the performance gap between textual-form and binary data formats.